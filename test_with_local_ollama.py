"""
æœ¬åœ°æµ‹è¯•è„šæœ¬ï¼šä½¿ç”¨ Ollama + Qwen3:1.7b æµ‹è¯• HippoRAG è®°å¿†ç®¡ç†ç³»ç»Ÿ

å‰ç½®æ¡ä»¶ï¼š
1. å·²å®‰è£… ollama
2. å·²æ‹‰å– Qwen3:1.7b æ¨¡å‹ï¼šollama pull qwen3:1.7b
3. è¿è¡Œ ollama serve (é»˜è®¤ç›‘å¬ http://localhost:11434)
"""

import logging
import json
import time
from typing import List, Dict, Tuple, Optional
import requests

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class OllamaQwenWrapper:
    """Ollama + Qwen çš„ç®€å•åŒ…è£…"""
    
    def __init__(self, model_name: str = "qwen3:1.7b", 
                 base_url: str = "http://localhost:11434",
                 temperature: float = 0.7):
        """
        Args:
            model_name: æ¨¡å‹åç§° (é»˜è®¤ qwen3:1.7b)
            base_url: ollama æœåŠ¡åœ°å€
            temperature: ç”Ÿæˆæ¸©åº¦ (0-1, è¶Šä½è¶Šç¡®å®š)
        """
        self.model_name = model_name
        self.base_url = base_url
        self.temperature = temperature
        self.api_endpoint = f"{base_url}/api/generate"
        
        # æ£€æŸ¥è¿æ¥
        self._check_connection()
    
    def _check_connection(self):
        """æ£€æŸ¥ ollama æœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=2)
            if response.status_code == 200:
                logger.info(f"âœ… Ollama æœåŠ¡è¿æ¥æˆåŠŸ")
                models = response.json().get("models", [])
                model_names = [m["name"] for m in models]
                logger.info(f"   å¯ç”¨æ¨¡å‹: {', '.join(model_names)}")
            else:
                raise Exception("Ollama æœåŠ¡è¿”å›é”™è¯¯")
        except requests.exceptions.ConnectionError:
            logger.error(f"âŒ æ— æ³•è¿æ¥åˆ° Ollama æœåŠ¡ ({self.base_url})")
            logger.error("   è¯·ç¡®ä¿å·²è¿è¡Œ: ollama serve")
            raise
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥ Ollama æœåŠ¡å‡ºé”™: {e}")
            raise
    
    def generate(self, prompt: str, max_tokens: int = 200) -> str:
        """
        ä½¿ç”¨ Qwen ç”Ÿæˆæ–‡æœ¬
        
        Args:
            prompt: æç¤ºæ–‡æœ¬
            max_tokens: æœ€å¤§ç”Ÿæˆä»¤ç‰Œæ•°
        
        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬
        """
        try:
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "temperature": self.temperature,
                "num_predict": max_tokens,
                "stream": False  # ä¸ä½¿ç”¨æµå¼è¾“å‡ºï¼Œä¾¿äºå¤„ç†
            }
            
            logger.debug(f"å‘é€è¯·æ±‚åˆ° Ollama...")
            start_time = time.time()
            
            response = requests.post(
                self.api_endpoint,
                json=payload,
                timeout=60  # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œå› ä¸ºæ¨¡å‹è¾ƒå°å¯èƒ½éœ€è¦æ—¶é—´
            )
            
            elapsed_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                generated_text = result.get("response", "").strip()
                logger.debug(f"âœ… ç”Ÿæˆå®Œæˆ ({elapsed_time:.2f}s)")
                return generated_text
            else:
                logger.error(f"âŒ Ollama API è¿”å›é”™è¯¯: {response.status_code}")
                return ""
        
        except requests.exceptions.Timeout:
            logger.error("âŒ è¯·æ±‚è¶…æ—¶ï¼ŒQwen æ¨¡å‹ç”Ÿæˆè€—æ—¶è¿‡é•¿")
            return ""
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ–‡æœ¬å‡ºé”™: {e}")
            return ""
    
    def extract_facts(self, text: str) -> List[Tuple[str, str, str]]:
        """
        ä½¿ç”¨ Qwen ä»æ–‡æœ¬ä¸­æå–äº‹å®ä¸‰å…ƒç»„
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
        
        Returns:
            äº‹å®ä¸‰å…ƒç»„åˆ—è¡¨ [(subject, predicate, object), ...]
        """
        prompt = f"""è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å…³é”®äº‹å®ï¼Œæ ¼å¼ä¸º(ä¸»ä½“, å…³ç³», å®¾ä½“)ã€‚
        åªåˆ—å‡ºäº‹å®ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜ã€‚
        
        æ–‡æœ¬: {text}
        
        äº‹å®:"""
        
        response = self.generate(prompt, max_tokens=150)
        
        # è§£æè¾“å‡º
        facts = []
        for line in response.split('\n'):
            line = line.strip()
            if line and '(' in line and ')' in line:
                try:
                    # ç®€å•çš„è§£æé€»è¾‘
                    content = line.replace('(', '').replace(')', '').strip()
                    parts = [p.strip() for p in content.split(',')]
                    if len(parts) == 3:
                        facts.append(tuple(parts))
                except:
                    pass
        
        return facts if facts else [("unknown", "property", "value")]
    
    def answer_question(self, question: str, context: str = "") -> str:
        """
        ä½¿ç”¨ Qwen å›ç­”é—®é¢˜
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            context: å¯é€‰çš„èƒŒæ™¯ä¿¡æ¯
        
        Returns:
            ç­”æ¡ˆ
        """
        if context:
            prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹èƒŒæ™¯ä¿¡æ¯å›ç­”é—®é¢˜ã€‚

èƒŒæ™¯ä¿¡æ¯: {context}

é—®é¢˜: {question}

ç­”æ¡ˆ:"""
        else:
            prompt = f"""é—®é¢˜: {question}

ç­”æ¡ˆ:"""
        
        answer = self.generate(prompt, max_tokens=200)
        return answer if answer else "æ— æ³•ç”Ÿæˆç­”æ¡ˆ"


class LocalOllamaRAGTest:
    """
    ä½¿ç”¨æœ¬åœ° Ollama + Qwen æµ‹è¯• HippoRAG è®°å¿†ç®¡ç†ç³»ç»Ÿ
    """
    
    def __init__(self, rag_system, llm: Optional[OllamaQwenWrapper] = None):
        """
        Args:
            rag_system: HippoRAG å®ä¾‹
            llm: OllamaQwenWrapper å®ä¾‹ï¼ˆå¦‚æœä¸ºNoneï¼Œä¼šè‡ªåŠ¨åˆå§‹åŒ–ï¼‰
        """
        self.rag = rag_system
        self.llm = llm or OllamaQwenWrapper()
        self.test_results = []
    
    # ========================================================================
    # æµ‹è¯•1: æ¿€æ´»åˆ†æ•°åŠ¨æ€å˜åŒ–
    # ========================================================================
    
    def test_1_activation_dynamics(self):
        """
        æµ‹è¯•1: éšç€æŸ¥è¯¢åºåˆ—ï¼Œæ¿€æ´»åˆ†æ•°å¦‚ä½•å˜åŒ–
        
        åœºæ™¯ï¼šåŒä¸€ä¸ªentityè¢«å¤šä¸ªç›¸å…³æŸ¥è¯¢æ¿€æ´»ï¼Œè§‚å¯Ÿå…¶æ¿€æ´»åˆ†æ•°å˜åŒ–
        """
        logger.info("\n" + "="*80)
        logger.info("æµ‹è¯•1: æ¿€æ´»åˆ†æ•°åŠ¨æ€å˜åŒ–")
        logger.info("="*80)
        
        # å‡†å¤‡æµ‹è¯•æ–‡æœ¬
        test_docs = [
            "Erik Hort is a notable historical figure. He was born in Montebello, a town known for its rich history.",
            "Montebello is a small town in New York, part of Rockland County. It has a population of around 3000 residents.",
            "Rockland County is located in the Hudson Valley region of New York. It borders New Jersey across the Hudson River."
        ]
        
        logger.info(f"\nğŸ“„ æ·»åŠ  {len(test_docs)} ä¸ªæµ‹è¯•æ–‡æ¡£...")
        try:
            self.rag.add(test_docs)
            logger.info("âœ… æ–‡æ¡£æ·»åŠ æˆåŠŸ\n")
        except Exception as e:
            logger.warning(f"âš ï¸  æ–‡æ¡£æ·»åŠ å¤±è´¥: {e}")
        
        # æ‰§è¡ŒæŸ¥è¯¢åºåˆ—
        queries = [
            "Who is Erik Hort?",
            "Where was Erik born?",
            "What is Montebello?",
            "Is Montebello in Rockland County?"
        ]
        
        logger.info(f"ğŸ“‹ æ‰§è¡Œ {len(queries)} ä¸ªç›¸å…³æŸ¥è¯¢:\n")
        
        for i, query in enumerate(queries, 1):
            logger.info(f"æŸ¥è¯¢ {i}: {query}")
            
            # æ‰§è¡Œæ£€ç´¢
            try:
                results = self.rag.retrieve(query)
                logger.info(f"  âœ… æ£€ç´¢å®Œæˆï¼Œè¿”å› {len(results)} æ¡ç»“æœ")
            except Exception as e:
                logger.warning(f"  âš ï¸  æ£€ç´¢å¤±è´¥: {e}")
                results = []
            
            # æœ€åä¸€ä¸ªæŸ¥è¯¢åæ£€æŸ¥æ¿€æ´»çŠ¶æ€
            if i == len(queries):
                logger.info(f"\nğŸ§  æœ€åæŸ¥è¯¢çš„æ¿€æ´»çŠ¶æ€åˆ†æ:\n")
                try:
                    activation = self.rag.get_memory_activation_status(query)
                    if 'error' not in activation:
                        self._print_activation_analysis(activation)
                    else:
                        logger.warning(f"âš ï¸  è·å–æ¿€æ´»çŠ¶æ€å¤±è´¥")
                except Exception as e:
                    logger.warning(f"âš ï¸  è·å–æ¿€æ´»çŠ¶æ€å‡ºé”™: {e}")
        
        logger.info(f"\nâœ… æµ‹è¯•1å®Œæˆ: é«˜åº¦ç›¸å…³çš„è®°å¿†æ¿€æ´»åº¦åº”è¯¥è¾ƒé«˜ï¼Œæ— å…³çš„è¾ƒä½\n")
    
    # ========================================================================
    # æµ‹è¯•2: è‡ªåŠ¨æ¶ˆé€€åŠŸèƒ½
    # ========================================================================
    
    def test_2_auto_decay(self):
        """
        æµ‹è¯•2: è‡ªåŠ¨æ¶ˆé€€ä½æ¿€æ´»è®°å¿†
        
        åœºæ™¯ï¼šåœ¨æŸ¥è¯¢ç‰¹å®šä¸»é¢˜åï¼Œä¸å…¶ä»–ä¸»é¢˜ç›¸å…³çš„è®°å¿†è¢«æ ‡è®°ä¸ºä½æ¿€æ´»ï¼Œç„¶ååˆ é™¤
        """
        logger.info("\n" + "="*80)
        logger.info("æµ‹è¯•2: è‡ªåŠ¨æ¶ˆé€€åŠŸèƒ½")
        logger.info("="*80)
        
        # è·å–ä»»æ„ä¸€ä¸ªæŸ¥è¯¢æ¥è®¡ç®—æ¿€æ´»åˆ†æ•°
        test_query = "What is Montebello?"
        
        logger.info(f"\nğŸ“Š æ¶ˆé€€å‰çš„è®°å¿†ç»Ÿè®¡:")
        
        try:
            # è·å–æ¶ˆé€€å‰çš„ç»Ÿè®¡
            chunk_ids_before = len(self.rag.chunk_embedding_store.get_all_ids())
            entity_ids_before = len(self.rag.entity_embedding_store.get_all_ids())
            fact_ids_before = len(self.rag.fact_embedding_store.get_all_ids())
            
            logger.info(f"  - Chunks: {chunk_ids_before}")
            logger.info(f"  - Entities: {entity_ids_before}")
            logger.info(f"  - Facts: {fact_ids_before}")
            
            # æ‰§è¡Œè‡ªåŠ¨æ¶ˆé€€
            logger.info(f"\nğŸ”„ æ‰§è¡Œè‡ªåŠ¨æ¶ˆé€€ (retention_ratio=0.8)...")
            decay_stats = self.rag.apply_context_aware_memory_decay(
                current_query=test_query,
                retention_ratio=0.8,  # ä¿ç•™80%ï¼Œåˆ é™¤20%
                auto_forget=True
            )
            
            logger.info(f"\nğŸ“Š æ¶ˆé€€åçš„è®°å¿†ç»Ÿè®¡:")
            logger.info(f"  - Chunks æ ‡è®°åˆ é™¤: {len(decay_stats['chunks_to_forget'])}")
            logger.info(f"  - Entities æ ‡è®°åˆ é™¤: {len(decay_stats['entities_to_forget'])}")
            logger.info(f"  - Facts æ ‡è®°åˆ é™¤: {len(decay_stats['facts_to_forget'])}")
            
            if 'auto_forgot_chunks' in decay_stats:
                logger.info(f"  - å®é™…åˆ é™¤çš„æ–‡æ¡£: {decay_stats['auto_forgot_chunks']}")
            
            logger.info(f"\nâœ… æ¶ˆé€€å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"âš ï¸  æ¶ˆé€€å‡ºé”™: {e}")
    
    # ========================================================================
    # æµ‹è¯•3: å†²çªæ£€æµ‹ä¸è§£å†³
    # ========================================================================
    
    def test_3_conflict_resolution(self):
        """
        æµ‹è¯•3: æ£€æµ‹å¹¶è§£å†³äº‹å®å†²çª
        
        åœºæ™¯ï¼šå¯¼å…¥æ–°ä¿¡æ¯ä¸ç°æœ‰çŸ¥è¯†å†²çªï¼Œè‡ªåŠ¨ç”¨æ–°å€¼è¦†ç›–æ—§å€¼
        """
        logger.info("\n" + "="*80)
        logger.info("æµ‹è¯•3: å†²çªæ£€æµ‹ä¸è§£å†³")
        logger.info("="*80)
        
        # æ¨¡æ‹Ÿæ–°æ·»åŠ çš„äº‹å®ï¼ˆä¸åŸæœ‰æ–‡æ¡£ä¿¡æ¯å†²çªï¼‰
        new_facts = [
            ("Erik Hort", "birthplace", "Rockland County"),  # ä¸åŸæ–‡æœ¬å†²çª
            ("Montebello", "location", "Rockland County"),   # ä¸åŸæ–‡æœ¬å†²çª
            ("Alice Smith", "profession", "historian")       # æ–°äº‹å®ï¼Œæ— å†²çª
        ]
        
        logger.info(f"\nğŸ“š æ–°æ·»åŠ çš„äº‹å®:")
        for i, fact in enumerate(new_facts, 1):
            logger.info(f"  {i}. {fact}")
        
        logger.info(f"\nğŸ” æ£€æµ‹å†²çª...")
        
        try:
            conflict_result = self.rag.detect_and_resolve_fact_conflicts(
                new_facts=new_facts,
                resolution_strategy='keep_new',  # æ–°å€¼è¦†ç›–æ—§å€¼
                auto_apply=True
            )
            
            logger.info(f"\nâš ï¸  å†²çªæ£€æµ‹ç»“æœ:")
            logger.info(f"  - æ£€æµ‹åˆ°çš„å†²çª: {conflict_result.get('conflicts_detected', 0)}")
            logger.info(f"  - è¦åˆ é™¤çš„æ—§äº‹å®: {len(conflict_result.get('facts_to_delete', []))}")
            logger.info(f"  - è¦åˆå¹¶çš„äº‹å®: {len(conflict_result.get('facts_to_merge', []))}")
            
            if conflict_result.get('conflict_records'):
                logger.info(f"\nğŸ“‹ å†²çªè¯¦æƒ…:")
                for i, record in enumerate(conflict_result['conflict_records'][:3], 1):
                    logger.info(f"  {i}. {record}")
            
            logger.info(f"\nâœ… å·²åº”ç”¨ 'keep_new' ç­–ç•¥ï¼Œæ–°å€¼è¦†ç›–æ—§å€¼")
            
        except Exception as e:
            logger.warning(f"âš ï¸  å†²çªå¤„ç†å‡ºé”™: {e}")
    
    # ========================================================================
    # æµ‹è¯•4: æ‰‹åŠ¨æ¸…é™¤ï¼ˆä¸¤æ­¥æµç¨‹ï¼‰
    # ========================================================================
    
    def test_4_manual_cleanup(self):
        """
        æµ‹è¯•4: æ‰‹åŠ¨æ¸…é™¤ä½æ¿€æ´»è®°å¿†
        
        åœºæ™¯ï¼šç”¨æˆ·å¯ä»¥å…ˆé¢„è§ˆè¦åˆ é™¤çš„é¡¹ç›®ï¼Œç„¶åç¡®è®¤åˆ é™¤
        """
        logger.info("\n" + "="*80)
        logger.info("æµ‹è¯•4: æ‰‹åŠ¨æ¸…é™¤ä½æ¿€æ´»è®°å¿†")
        logger.info("="*80)
        
        test_query = "What is Rockland County?"
        
        # ç¬¬ä¸€æ­¥ï¼šé¢„è§ˆ
        logger.info(f"\nğŸ“‹ æ­¥éª¤1: é¢„è§ˆæ¨¡å¼ (dry_run=True)")
        logger.info(f"   æŸ¥æ‰¾æ¿€æ´»åˆ†æ•° < 0.15 çš„è®°å¿†\n")
        
        try:
            preview = self.rag.manual_cleanup_low_activation_memories(
                current_query=test_query,
                activation_threshold=0.15,
                dry_run=True  # ä¸å®é™…åˆ é™¤
            )
            
            logger.info(f"ğŸ“Š é¢„è§ˆç»“æœ:")
            logger.info(f"  - ä½æ¿€æ´» Chunks: {len(preview.get('chunks_to_delete', []))}")
            logger.info(f"  - ä½æ¿€æ´» Entities: {len(preview.get('entities_to_delete', []))}")
            logger.info(f"  - ä½æ¿€æ´» Facts: {len(preview.get('facts_to_delete', []))}")
            
            # ç¬¬äºŒæ­¥ï¼šç¡®è®¤åˆ é™¤
            logger.info(f"\nâœ… ç”¨æˆ·å®¡æŸ¥å®Œæˆï¼Œç¡®è®¤åˆ é™¤\n")
            
            logger.info(f"ğŸ”§ æ­¥éª¤2: æ‰§è¡Œæ¨¡å¼ (dry_run=False)")
            logger.info(f"   å¼€å§‹å®é™…åˆ é™¤\n")
            
            result = self.rag.manual_cleanup_low_activation_memories(
                current_query=test_query,
                activation_threshold=0.15,
                dry_run=False  # å®é™…åˆ é™¤
            )
            
            if 'actually_deleted_count' in result:
                logger.info(f"âœ… æ¸…é™¤å®Œæˆ: åˆ é™¤äº† {result['actually_deleted_count']} ä¸ªæ–‡æ¡£")
            else:
                logger.info(f"âœ… æ¸…é™¤å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"âš ï¸  æ‰‹åŠ¨æ¸…é™¤å‡ºé”™: {e}")
    
    # ========================================================================
    # æµ‹è¯•5: ä½¿ç”¨ Qwen LLM çš„å®Œæ•´å¯¹è¯æµç¨‹
    # ========================================================================
    
    def test_5_llm_integration(self):
        """
        æµ‹è¯•5: é›†æˆ Qwen LLM çš„å®Œæ•´å¯¹è¯
        
        åœºæ™¯ï¼š
        1. ç”¨æˆ·æé—®
        2. RAG æ£€ç´¢ç›¸å…³æ–‡æ¡£
        3. Qwen ç”Ÿæˆç­”æ¡ˆ
        4. è®°å½•è®¿é—®å†å²
        5. è‡ªåŠ¨åº”ç”¨æ¶ˆé€€
        """
        logger.info("\n" + "="*80)
        logger.info("æµ‹è¯•5: Qwen LLM é›†æˆå¯¹è¯")
        logger.info("="*80)
        
        # å¯¹è¯åºåˆ—
        conversation = [
            "Who is Erik Hort?",
            "Where was he born?",
            "Tell me about Montebello."
        ]
        
        logger.info(f"\nğŸ’¬ å¼€å§‹ {len(conversation)} è½®å¯¹è¯\n")
        
        for i, question in enumerate(conversation, 1):
            logger.info(f"è½®æ¬¡ {i}:")
            logger.info(f"ğŸ‘¤ ç”¨æˆ·: {question}\n")
            
            # æ­¥éª¤1: RAG æ£€ç´¢
            logger.info(f"  [æ­¥éª¤1] RAG æ£€ç´¢ç›¸å…³æ–‡æ¡£...")
            try:
                retrieved_docs = self.rag.retrieve(question)
                logger.info(f"  âœ… æ£€ç´¢å®Œæˆï¼Œå¾—åˆ° {len(retrieved_docs)} æ¡æ–‡æ¡£\n")
                
                # ç»„ç»‡ä¸Šä¸‹æ–‡
                context = "\n".join([
                    doc.get('content', str(doc))[:200] 
                    for doc in retrieved_docs[:2]
                ])
            except Exception as e:
                logger.warning(f"  âš ï¸  æ£€ç´¢å¤±è´¥: {e}")
                context = ""
            
            # æ­¥éª¤2: Qwen ç”Ÿæˆç­”æ¡ˆ
            logger.info(f"  [æ­¥éª¤2] Qwen ç”Ÿæˆç­”æ¡ˆ...")
            try:
                answer = self.llm.answer_question(question, context=context)
                logger.info(f"  âœ… ç­”æ¡ˆç”Ÿæˆå®Œæˆ\n")
            except Exception as e:
                logger.warning(f"  âš ï¸  ç”Ÿæˆå¤±è´¥: {e}")
                answer = "æ— æ³•ç”Ÿæˆç­”æ¡ˆ"
            
            # è¾“å‡ºç­”æ¡ˆ
            logger.info(f"ğŸ¤– Qwen: {answer}\n")
            
            # æ­¥éª¤3: ä¿å­˜ç»“æœ
            self.test_results.append({
                'turn': i,
                'question': question,
                'answer': answer,
                'docs_retrieved': len(retrieved_docs) if retrieved_docs else 0
            })
            
            # æœ€åä¸€ä¸ªé—®é¢˜ååº”ç”¨æ¶ˆé€€
            if i == len(conversation):
                logger.info(f"  [æ­¥éª¤3] å¯¹è¯ç»“æŸï¼Œåº”ç”¨è‡ªåŠ¨æ¶ˆé€€...\n")
                try:
                    decay_stats = self.rag.apply_context_aware_memory_decay(
                        current_query=question,
                        retention_ratio=0.85,
                        auto_forget=True
                    )
                    logger.info(f"  âœ… æ¶ˆé€€å®Œæˆ\n")
                except Exception as e:
                    logger.warning(f"  âš ï¸  æ¶ˆé€€å¤±è´¥: {e}\n")
        
        logger.info(f"âœ… å¯¹è¯æµ‹è¯•å®Œæˆ\n")
    
    # ========================================================================
    # æµ‹è¯•6: å†…å­˜æ¿€æ´»çŠ¶æ€è¯Šæ–­
    # ========================================================================
    
    def test_6_activation_diagnostics(self):
        """
        æµ‹è¯•6: æ·±å…¥è¯Šæ–­å½“å‰å†…å­˜çš„æ¿€æ´»çŠ¶æ€
        
        è¿™æœ‰åŠ©äºç†è§£è®°å¿†ç³»ç»Ÿçš„å·¥ä½œæƒ…å†µ
        """
        logger.info("\n" + "="*80)
        logger.info("æµ‹è¯•6: å†…å­˜æ¿€æ´»çŠ¶æ€è¯Šæ–­")
        logger.info("="*80)
        
        test_query = "What is Montebello?"
        
        logger.info(f"\nğŸ” è¯Šæ–­æŸ¥è¯¢: {test_query}\n")
        
        try:
            activation = self.rag.get_memory_activation_status(test_query)
            
            if 'error' in activation:
                logger.warning(f"âš ï¸  è·å–æ¿€æ´»çŠ¶æ€å¤±è´¥")
                return
            
            self._print_activation_analysis(activation)
            
            # é¢å¤–çš„è¯Šæ–­ä¿¡æ¯
            logger.info(f"\nğŸ“Š è¯¦ç»†ç»Ÿè®¡:")
            
            for mem_type in ['chunk', 'entity', 'fact']:
                key = f'{mem_type}_activation'
                if key in activation:
                    stats = activation[key]
                    total = stats['total_count']
                    if total > 0:
                        high_ratio = stats['high_activation_count'] / total * 100
                        logger.info(f"  {mem_type.upper()}: {high_ratio:.1f}% å¤„äºé«˜æ¿€æ´»çŠ¶æ€")
            
        except Exception as e:
            logger.warning(f"âš ï¸  è¯Šæ–­å‡ºé”™: {e}")
    
    # ========================================================================
    # è¾…åŠ©æ–¹æ³•
    # ========================================================================
    
    def _print_activation_analysis(self, activation: Dict):
        """æ‰“å°æ¿€æ´»çŠ¶æ€åˆ†æ"""
        logger.info(f"ğŸ“ˆ æ¿€æ´»çŠ¶æ€åˆ†æ:")
        
        for mem_type in ['chunk', 'entity', 'fact']:
            key = f'{mem_type}_activation'
            if key in activation:
                stats = activation[key]
                
                if stats['total_count'] == 0:
                    logger.info(f"\n  {mem_type.upper()}: (æ— æ•°æ®)")
                    continue
                
                logger.info(f"\n  {mem_type.upper()}:")
                logger.info(f"    - æ€»æ•°: {stats['total_count']}")
                logger.info(f"    - é«˜æ¿€æ´» (>0.7): {stats['high_activation_count']} ({stats['high_activation_count']/stats['total_count']*100:.1f}%)")
                logger.info(f"    - ä¸­æ¿€æ´» (0.3-0.7): {stats['medium_activation_count']} ({stats['medium_activation_count']/stats['total_count']*100:.1f}%)")
                logger.info(f"    - ä½æ¿€æ´» (0.05-0.3): {stats['low_activation_count']} ({stats['low_activation_count']/stats['total_count']*100:.1f}%)")
                logger.info(f"    - éæ´»è·ƒ (â‰¤0.05): {stats['inactive_count']} ({stats['inactive_count']/stats['total_count']*100:.1f}%)")
                logger.info(f"    - å¹³å‡æ¿€æ´»åº¦: {stats['avg_activation']:.3f}")
                logger.info(f"    - æœ€å¤§æ¿€æ´»åº¦: {stats['max_activation']:.3f}")
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("""
        
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  HippoRAG è®°å¿†ç®¡ç†ç³»ç»Ÿ - æœ¬åœ° Ollama æµ‹è¯•                   â•‘
â•‘                      ä½¿ç”¨ Qwen3:1.7b æ¨¡å‹                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)
        
        tests = [
            ("æ¿€æ´»åˆ†æ•°åŠ¨æ€å˜åŒ–", self.test_1_activation_dynamics),
            ("è‡ªåŠ¨æ¶ˆé€€åŠŸèƒ½", self.test_2_auto_decay),
            ("å†²çªæ£€æµ‹ä¸è§£å†³", self.test_3_conflict_resolution),
            ("æ‰‹åŠ¨æ¸…é™¤åŠŸèƒ½", self.test_4_manual_cleanup),
            ("Qwen LLM é›†æˆ", self.test_5_llm_integration),
            ("æ¿€æ´»çŠ¶æ€è¯Šæ–­", self.test_6_activation_diagnostics)
        ]
        
        results_summary = []
        
        for test_name, test_func in tests:
            try:
                test_func()
                results_summary.append((test_name, "âœ… é€šè¿‡"))
            except Exception as e:
                logger.error(f"âŒ {test_name} å¤±è´¥: {e}")
                results_summary.append((test_name, f"âŒ å¤±è´¥: {str(e)[:50]}"))
        
        # æ‰“å°æ€»ç»“
        logger.info("\n" + "="*80)
        logger.info("æµ‹è¯•æ€»ç»“")
        logger.info("="*80)
        
        for test_name, result in results_summary:
            logger.info(f"{test_name:20} {result}")
        
        logger.info("="*80)


def main():
    """
    ä½¿ç”¨ç¤ºä¾‹
    """
    try:
        # åˆå§‹åŒ– Ollama Qwen
        logger.info("åˆå§‹åŒ– Ollama Qwen LLM...")
        llm = OllamaQwenWrapper(
            model_name="qwen3:1.7b",
            base_url="http://localhost:11434",
            temperature=0.7
        )
        logger.info("âœ… Qwen LLM åˆå§‹åŒ–æˆåŠŸ\n")
        
        # è¿™é‡Œéœ€è¦ä½ å·²ç»åˆå§‹åŒ–å¥½ HippoRAG
        # å¦‚æœä½ çš„ HippoRAG åˆå§‹åŒ–éœ€è¦ç‰¹å®šé…ç½®ï¼Œè¯·ä¿®æ”¹ä¸‹é¢çš„ä»£ç 
        
        # ç¤ºä¾‹ 1: å¦‚æœä½ æœ‰ç°æˆçš„ RAG å®ä¾‹
        # from src.hipporag import HippoRAG
        # rag = HippoRAG(config)
        
        # ç¤ºä¾‹ 2: å¦‚æœéœ€è¦åˆ›å»ºæµ‹è¯•ç”¨çš„ RAG
        # è¯·å–æ¶ˆæ³¨é‡Šå¹¶æ ¹æ®ä½ çš„é…ç½®ä¿®æ”¹
        
        logger.error("âš ï¸  éœ€è¦åˆå§‹åŒ– HippoRAG å®ä¾‹")
        logger.error("   è¯·ä¿®æ”¹ main() å‡½æ•°ï¼Œæ·»åŠ ä½ çš„ HippoRAG åˆå§‹åŒ–ä»£ç ")
        logger.error("\n   ä¾‹å¦‚:")
        logger.error("   from src.hipporag import HippoRAG")
        logger.error("   rag = HippoRAG(your_config)")
        logger.error("   ")
        logger.error("   ç„¶åå–æ¶ˆæ³¨é‡Šä¸‹é¢çš„ä»£ç ")
        
        # # åˆ›å»ºæµ‹è¯•å¯¹è±¡
        # test = LocalOllamaRAGTest(rag, llm)
        # 
        # # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        # test.run_all_tests()
        
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")


if __name__ == "__main__":
    main()
