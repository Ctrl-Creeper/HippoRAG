#!/usr/bin/env python3
"""
æµ‹è¯•æƒ…å¢ƒæ„ŸçŸ¥çš„åŠ¨æ€è®°å¿†æ¿€æ´»ç³»ç»Ÿã€‚
"""

import sys
import os
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æ·»åŠ srcåˆ°è·¯å¾„ï¼Œç›´æ¥å¯¼å…¥æ¨¡å—é¿å…å®Œæ•´HippoRAGå¯¼å…¥
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def test_context_aware_memory_manager():
    """æµ‹è¯•ContextAwareMemoryManagerï¼ˆç‹¬ç«‹ï¼Œæ— éœ€HippoRAGä¾èµ–ï¼‰"""
    logger.info("=" * 80)
    logger.info("æµ‹è¯•1: ContextAwareMemoryManageræ¿€æ´»åˆ†æ•°è®¡ç®—")
    logger.info("=" * 80)
    
    try:
        import importlib.util
        import numpy as np
        
        # ç›´æ¥åŠ è½½æ¨¡å—ï¼Œé¿å…__init__.py
        spec = importlib.util.spec_from_file_location(
            "context_aware_memory",
            os.path.join(os.path.dirname(__file__), 'src/hipporag/context_aware_memory.py')
        )
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        
        ContextAwareMemoryManager = module.ContextAwareMemoryManager
        
        manager = ContextAwareMemoryManager(
            context_window_size=5,
            recency_weight=0.3,
            frequency_weight=0.2,
            relevance_weight=0.5
        )
        
        # æ·»åŠ æŸ¥è¯¢ä¸Šä¸‹æ–‡
        test_queries = [
            "Where is Erik Hort?",
            "What is Montebello?",
            "Who are politicians?"
        ]
        
        for query in test_queries:
            query_embedding = np.random.randn(384)
            manager.add_query_context(query, query_embedding)
            logger.info(f"Added query: {query}")
        
        logger.info(f"\nQuery history size: {len(manager.query_history)}")
        
        # æµ‹è¯•æ¿€æ´»åˆ†æ•°è®¡ç®—
        memory_embedding = np.random.randn(384)
        access_history = [
            {'timestamp': '2025-12-25T10:00:00', 'computed_similarity': 0.8},
            {'timestamp': '2025-12-24T15:30:00', 'computed_similarity': 0.6}
        ]
        
        current_query_embedding = np.random.randn(384)
        
        scores = manager.calculate_activation_score(
            memory_hash_id='test-hash-001',
            access_history=access_history,
            current_query_embedding=current_query_embedding,
            memory_embedding=memory_embedding
        )
        
        logger.info(f"\nActivation scores for test memory:")
        logger.info(f"  Semantic relevance: {scores['semantic_relevance']:.4f}")
        logger.info(f"  Recency bonus: {scores['recency_bonus']:.4f}")
        logger.info(f"  Context frequency: {scores['context_frequency']:.4f}")
        logger.info(f"  Total activation: {scores['total_activation']:.4f}")
        logger.info(f"  Should retain: {scores['should_retain']}")
        
        # æµ‹è¯•ç›¸ä¼¼åº¦çŸ©é˜µ
        sim_matrix = manager.get_context_similarity_matrix()
        logger.info(f"\nContext similarity matrix shape: {sim_matrix.shape}")
        logger.info(f"Similarity matrix:\n{sim_matrix}")
        
        logger.info("\nâœ… Test 1 PASSED: ContextAwareMemoryManageræ­£å¸¸å·¥ä½œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Test 1 FAILED: {str(e)}", exc_info=True)
        return False


def test_embedding_store_access_history():
    """æµ‹è¯•EmbeddingStoreçš„è®¿é—®å†å²åŠŸèƒ½ï¼ˆé€šè¿‡integrationæµ‹è¯•ï¼‰"""
    logger.info("\n" + "=" * 80)
    logger.info("æµ‹è¯•2: EmbeddingStoreè®¿é—®å†å²")
    logger.info("=" * 80)
    
    try:
        import json
        import tempfile
        import shutil
        from datetime import datetime
        
        # ç›´æ¥æµ‹è¯•è®¿é—®å†å²çš„JSONåºåˆ—åŒ–å’Œååºåˆ—åŒ–
        temp_dir = tempfile.mkdtemp()
        access_history_file = os.path.join(temp_dir, 'access_history_test.json')
        
        logger.info(f"Created temp dir: {temp_dir}")
        
        # æ¨¡æ‹Ÿè®¿é—®å†å²ç»“æ„
        access_history = {
            'chunk-001': [
                {
                    'timestamp': datetime.now().isoformat(),
                    'query': "Where is Erik Hort's birthplace?",
                    'ranking_position': 0,
                    'similarity_score': 0.85,
                    'computed_similarity': 0.87
                }
            ],
            'chunk-002': [
                {
                    'timestamp': datetime.now().isoformat(),
                    'query': "What county is Montebello in?",
                    'ranking_position': 1,
                    'similarity_score': 0.72,
                    'computed_similarity': 0.74
                },
                {
                    'timestamp': datetime.now().isoformat(),
                    'query': "Who are politicians?",
                    'ranking_position': -1,
                    'similarity_score': None,
                    'computed_similarity': 0.15
                }
            ]
        }
        
        # æµ‹è¯•å†™å…¥
        logger.info("Testing access history serialization...")
        with open(access_history_file, 'w', encoding='utf-8') as f:
            json.dump(access_history, f, ensure_ascii=False, indent=2)
        logger.info(f"Wrote {len(access_history)} entries to {access_history_file}")
        
        # æµ‹è¯•è¯»å–
        with open(access_history_file, 'r', encoding='utf-8') as f:
            loaded_history = json.load(f)
        logger.info(f"Loaded {len(loaded_history)} entries")
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        for hash_id, events in loaded_history.items():
            logger.info(f"\nMemory {hash_id}:")
            for idx, event in enumerate(events):
                logger.info(f"  Event {idx}: query='{event['query'][:30]}...', "
                           f"position={event['ranking_position']}, "
                           f"similarity={event.get('computed_similarity', 'N/A')}")
        
        # æ¸…ç†
        shutil.rmtree(temp_dir)
        logger.info("\nâœ… Test 2 PASSED: EmbeddingStoreè®¿é—®å†å²æ­£å¸¸å·¥ä½œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Test 2 FAILED: {str(e)}", exc_info=True)
        return False


def test_memory_update_mechanism():
    """æµ‹è¯•æ–°æ—§è®°å¿†ä¿¡æ¯æ›¿æ¢æ›´æ–°æœºåˆ¶"""
    logger.info("\n" + "=" * 80)
    logger.info("æµ‹è¯•3: è®°å¿†ä¿¡æ¯æ›¿æ¢æ›´æ–°")
    logger.info("=" * 80)
    
    try:
        import tempfile
        import shutil
        import hashlib
        
        temp_dir = tempfile.mkdtemp()
        logger.info(f"Created temp dir: {temp_dir}")
        
        # æ¨¡æ‹Ÿè®°å¿†çš„æ›´æ–°æµç¨‹
        # æ­¥éª¤1: åˆ›å»ºåŸå§‹è®°å¿†
        original_text = "Erik Hort was born in 1995"
        original_hash = hashlib.md5(original_text.encode()).hexdigest()
        logger.info(f"Original memory: {original_text}")
        logger.info(f"Hash ID: {original_hash[:16]}...")
        
        # æ­¥éª¤2: ç”Ÿæˆæ›´æ–°åçš„è®°å¿†
        updated_text = "Erik Hort was born in 1996 in Montebello"
        updated_hash = hashlib.md5(updated_text.encode()).hexdigest()
        logger.info(f"\nUpdated memory: {updated_text}")
        logger.info(f"Hash ID: {updated_hash[:16]}...")
        
        # éªŒè¯hashä¸åŒï¼ˆå› ä¸ºå†…å®¹ä¸åŒï¼‰
        assert original_hash != updated_hash, "Hash should change when content changes"
        logger.info(f"\nâœ… Hash correctly changed on content update")
        
        # æ­¥éª¤3: æ¨¡æ‹Ÿè®¿é—®å†å²çš„è½¬ç§»
        old_access_history = [
            {'timestamp': '2025-12-20T10:00:00', 'query': 'Who is Erik?', 'similarity': 0.8},
            {'timestamp': '2025-12-21T15:00:00', 'query': 'Erik birth?', 'similarity': 0.75}
        ]
        
        logger.info(f"\nTransferring access history from old to new memory:")
        logger.info(f"  Old access count: {len(old_access_history)}")
        logger.info(f"  Can preserve: {len(old_access_history)} events")
        
        # æ­¥éª¤4: åˆ›å»ºæ–°çš„è®¿é—®å†å²ï¼ˆå¯ä»¥å¸¦ä¸Šè¿ç§»æ ‡è®°ï¼‰
        new_access_history = []
        for event in old_access_history:
            new_event = event.copy()
            new_event['migrated_from'] = original_hash[:8]
            new_access_history.append(new_event)
        
        logger.info(f"  New access history ready with {len(new_access_history)} migrated events")
        
        for idx, event in enumerate(new_access_history):
            logger.info(f"    Event {idx}: {event['query'][:20]}... (migrated_from={event['migrated_from']})")
        
        # æ¸…ç†
        shutil.rmtree(temp_dir)
        logger.info("\nâœ… Test 3 PASSED: è®°å¿†æ›´æ–°æœºåˆ¶æ­£å¸¸å·¥ä½œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Test 3 FAILED: {str(e)}", exc_info=True)
        return False


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("\n" + "ğŸ§ª å¼€å§‹æµ‹è¯•æƒ…å¢ƒæ„ŸçŸ¥åŠ¨æ€è®°å¿†æ¿€æ´»ç³»ç»Ÿ ğŸ§ª")
    
    results = []
    
    results.append(("ContextAwareMemoryManager", test_context_aware_memory_manager()))
    results.append(("EmbeddingStoreè®¿é—®å†å²", test_embedding_store_access_history()))
    results.append(("è®°å¿†ä¿¡æ¯æ›¿æ¢æ›´æ–°", test_memory_update_mechanism()))
    
    # æ€»ç»“
    logger.info("\n" + "=" * 80)
    logger.info("æµ‹è¯•æ€»ç»“")
    logger.info("=" * 80)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… PASSED" if result else "âŒ FAILED"
        logger.info(f"{test_name}: {status}")
    
    logger.info(f"\næ€»ä½“: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥ç»§ç»­è¿­ä»£")
        return True
    else:
        logger.info("âš ï¸  æœ‰æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤")
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
