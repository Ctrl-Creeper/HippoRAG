"""
é›†æˆæµ‹è¯•ï¼šä½¿ç”¨å¤§æ¨¡å‹æµ‹è¯•å®Œæ•´çš„è®°å¿†ç®¡ç†ç³»ç»Ÿ

å±•ç¤ºå¦‚ä½•åœ¨å®é™…RAGåº”ç”¨ä¸­è°ƒç”¨ä¸‰ä¸ªæ ¸å¿ƒAPIï¼š
1. apply_context_aware_memory_decay() - è‡ªåŠ¨æ¶ˆé€€
2. manual_cleanup_low_activation_memories() - æ‰‹åŠ¨æ¸…é™¤
3. detect_and_resolve_fact_conflicts() - å†²çªè§£å†³
"""

import logging
from typing import List, Dict, Tuple

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class LLMIntegrationTest:
    """å±•ç¤ºå¦‚ä½•åœ¨å¤§æ¨¡å‹åº”ç”¨ä¸­ä½¿ç”¨æ–°çš„è®°å¿†ç®¡ç†API"""
    
    def __init__(self, rag_system):
        """
        Args:
            rag_system: HippoRAGå®ä¾‹
        """
        self.rag = rag_system
        self.query_history = []
        self.conflict_records = []
    
    # ============================================================================
    # ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€æ£€ç´¢æµç¨‹ï¼ˆè‡ªåŠ¨é›†æˆï¼‰
    # ============================================================================
    
    def retrieve_with_auto_decay(self, query: str, enable_decay: bool = True) -> List[Dict]:
        """
        æ ‡å‡†æ£€ç´¢æµç¨‹ - è‡ªåŠ¨è§¦å‘æƒ…å¢ƒæ„ŸçŸ¥æ¶ˆé€€
        
        è¯´æ˜ï¼š
            retrieve()æ–¹æ³•å·²è¢«ä¿®æ”¹ï¼Œä¼šåœ¨è¿”å›ç»“æœåè‡ªåŠ¨ï¼š
            1. è®°å½•è®¿é—®å†å²
            2. æ›´æ–°æŸ¥è¯¢ä¸Šä¸‹æ–‡çª—å£
            3. ï¼ˆå¯é€‰ï¼‰è§¦å‘è‡ªåŠ¨æ¶ˆé€€
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            enable_decay: æ˜¯å¦å¯ç”¨è‡ªåŠ¨æ¶ˆé€€
        
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        
        ä½¿ç”¨ç¤ºä¾‹ï¼š
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"æŸ¥è¯¢ #{len(self.query_history)+1}: {query}")
        logger.info(f"{'='*80}")
        
        # æ‰§è¡Œæ ‡å‡†æ£€ç´¢
        results = self.rag.retrieve(query)
        self.query_history.append(query)
        
        logger.info(f"âœ… æ£€ç´¢å®Œæˆï¼Œè¿”å› {len(results)} æ¡ç»“æœ")
        logger.info(f"   - è®¿é—®å†å²å·²è‡ªåŠ¨è®°å½•")
        logger.info(f"   - æŸ¥è¯¢ä¸Šä¸‹æ–‡å·²æ›´æ–°")
        
        # å¯é€‰ï¼šåœ¨æ£€ç´¢åç«‹å³æŸ¥çœ‹æ¿€æ´»çŠ¶æ€
        if enable_decay:
            activation_status = self.rag.get_memory_activation_status(query)
            self._print_activation_status(activation_status)
        
        return results
    
    # ============================================================================
    # ç¬¬äºŒéƒ¨åˆ†ï¼šAPI #1 - è‡ªåŠ¨æ¶ˆé€€ï¼ˆæ¨èç”¨äºåå°ç»´æŠ¤ï¼‰
    # ============================================================================
    
    def test_auto_memory_decay(self, current_query: str, retention_ratio: float = 0.9):
        """
        API #1: åº”ç”¨æƒ…å¢ƒæ„ŸçŸ¥çš„è®°å¿†æ¶ˆé€€
        
        è¿™ä¸ªæ–¹æ³•ä¼šæ ¹æ®è®°å¿†ä¸å½“å‰æŸ¥è¯¢çš„ç›¸å…³æ€§è‡ªåŠ¨åˆ é™¤ä½æ¿€æ´»çš„è®°å¿†ã€‚
        
        Args:
            current_query: å½“å‰æŸ¥è¯¢ï¼ˆç”¨äºè®¡ç®—æ¿€æ´»åˆ†æ•°ï¼‰
            retention_ratio: ä¿ç•™æ¯”ä¾‹ï¼ˆ0.9 = ä¿ç•™æ¿€æ´»åº¦top-90%ï¼‰
        
        ä½¿ç”¨åœºæ™¯ï¼š
            - åœ¨çŸ¥è¯†åº“æ•°é‡å¢é•¿æ—¶å®šæœŸæ¸…ç†
            - åœ¨ç³»ç»Ÿæ£€ç´¢é€Ÿåº¦ä¸‹é™æ—¶è§¦å‘
            - åœ¨å†…å­˜ä¸è¶³æ—¶è‡ªåŠ¨è°ƒç”¨
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"API #1: åº”ç”¨è‡ªåŠ¨æ¶ˆé€€ (retention_ratio={retention_ratio})")
        logger.info(f"{'='*80}\n")
        
        decay_stats = self.rag.apply_context_aware_memory_decay(
            current_query=current_query,
            retention_ratio=retention_ratio,
            auto_forget=True  # è‡ªåŠ¨æ‰§è¡Œåˆ é™¤
        )
        
        logger.info(f"æ¶ˆé€€å‰çš„è®°å¿†æ•°é‡ï¼š")
        logger.info(f"  - Chunks: {decay_stats['total_chunks']}")
        logger.info(f"  - Entities: {decay_stats['total_entities']}")
        logger.info(f"  - Facts: {decay_stats['total_facts']}")
        
        logger.info(f"\næ¶ˆé€€åçš„è®°å¿†æ•°é‡ï¼š")
        logger.info(f"  - Chunks: {decay_stats['total_chunks'] - len(decay_stats['chunks_to_forget'])}")
        logger.info(f"  - Entities: {decay_stats['total_entities'] - len(decay_stats['entities_to_forget'])}")
        logger.info(f"  - Facts: {decay_stats['total_facts'] - len(decay_stats['facts_to_forget'])}")
        
        if 'auto_forgot_chunks' in decay_stats:
            logger.info(f"\nâœ… å·²è‡ªåŠ¨åˆ é™¤ {decay_stats['auto_forgot_chunks']} ä¸ªæ–‡æ¡£")
        
        return decay_stats
    
    # ============================================================================
    # ç¬¬ä¸‰éƒ¨åˆ†ï¼šAPI #2 - æ‰‹åŠ¨æ¸…é™¤ï¼ˆæ¨èç”¨äºäº¤äº’å¼å®¡æŸ¥ï¼‰
    # ============================================================================
    
    def test_manual_cleanup(self, current_query: str, activation_threshold: float = 0.1):
        """
        API #2: æ‰‹åŠ¨æ¸…é™¤ä½æ¿€æ´»è®°å¿†
        
        è¿™ä¸ªæ–¹æ³•å…è®¸ç”¨æˆ·æŸ¥çœ‹ä½æ¿€æ´»çš„è®°å¿†ï¼Œå¹¶åœ¨å®¡æŸ¥åæ‰‹åŠ¨åˆ é™¤ã€‚
        
        Args:
            current_query: å½“å‰æŸ¥è¯¢
            activation_threshold: æ¿€æ´»åˆ†æ•°é˜ˆå€¼ï¼ˆä½äºæ­¤å€¼çš„è®°å¿†è¢«æ ‡è®°ä¸ºåˆ é™¤ï¼‰
        
        ä½¿ç”¨åœºæ™¯ï¼š
            - ç”¨æˆ·å¸Œæœ›æ‰‹åŠ¨å®¡æŸ¥è¦åˆ é™¤çš„è®°å¿†
            - ç³»ç»Ÿç®¡ç†å‘˜æ¸…ç†çŸ¥è¯†åº“
            - åœ¨åˆ é™¤å‰è·å¾—ç”¨æˆ·ç¡®è®¤
        
        å®Œæ•´æµç¨‹ï¼š
            1. dry_run=Trueï¼šæŸ¥çœ‹å°†è¦åˆ é™¤çš„é¡¹ç›®
            2. ç”¨æˆ·å®¡æŸ¥å’Œç¡®è®¤
            3. dry_run=Falseï¼šæ‰§è¡Œå®é™…åˆ é™¤
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"API #2: æ‰‹åŠ¨æ¸…é™¤ä½æ¿€æ´»è®°å¿†")
        logger.info(f"{'='*80}\n")
        
        # ç¬¬ä¸€æ­¥ï¼šæ¼”ç»ƒæ¨¡å¼ï¼ˆä¸å®é™…åˆ é™¤ï¼‰
        logger.info(f"ğŸ“‹ æ¼”ç»ƒæ¨¡å¼ (dry_run=True)ï¼š")
        logger.info(f"   æŸ¥æ‰¾æ¿€æ´»åˆ†æ•° < {activation_threshold} çš„è®°å¿†\n")
        
        cleanup_preview = self.rag.manual_cleanup_low_activation_memories(
            current_query=current_query,
            activation_threshold=activation_threshold,
            dry_run=True  # ä»…é¢„è§ˆ
        )
        
        logger.info(f"ğŸ“Š å‘ç°ä»¥ä¸‹ä½æ¿€æ´»è®°å¿†ï¼š")
        logger.info(f"  - ä½æ¿€æ´»Chunksæ•°: {len(cleanup_preview['chunks_to_delete'])}")
        logger.info(f"  - ä½æ¿€æ´»Entitiesæ•°: {len(cleanup_preview['entities_to_delete'])}")
        logger.info(f"  - ä½æ¿€æ´»Factsæ•°: {len(cleanup_preview['facts_to_delete'])}")
        
        # ç¬¬äºŒæ­¥ï¼šç”¨æˆ·å®¡æŸ¥å’Œç¡®è®¤ï¼ˆæ¨¡æ‹Ÿè‡ªåŠ¨ç¡®è®¤ï¼‰
        logger.info(f"\nâœ… ç”¨æˆ·å®¡æŸ¥å®Œæˆï¼Œç¡®è®¤åˆ é™¤\n")
        
        # ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡Œåˆ é™¤
        logger.info(f"ğŸ”§ æ‰§è¡Œæ¨¡å¼ (dry_run=False)ï¼šå¼€å§‹å®é™…åˆ é™¤\n")
        
        cleanup_result = self.rag.manual_cleanup_low_activation_memories(
            current_query=current_query,
            activation_threshold=activation_threshold,
            dry_run=False  # æ‰§è¡Œåˆ é™¤
        )
        
        if 'error' not in cleanup_result:
            logger.info(f"âœ… æ¸…é™¤å®Œæˆï¼")
            if 'actually_deleted_count' in cleanup_result:
                logger.info(f"   å·²åˆ é™¤ {cleanup_result['actually_deleted_count']} ä¸ªæ–‡æ¡£")
        
        return cleanup_result
    
    # ============================================================================
    # ç¬¬å››éƒ¨åˆ†ï¼šAPI #3 - å†²çªæ£€æµ‹ä¸è§£å†³ï¼ˆæ¨èç”¨äºçŸ¥è¯†åº“æ›´æ–°ï¼‰
    # ============================================================================
    
    def test_conflict_detection_and_resolution(self, 
                                               new_facts: List[Tuple[str, str, str]],
                                               strategy: str = 'keep_new'):
        """
        API #3: æ£€æµ‹å¹¶è§£å†³äº‹å®å†²çª
        
        å½“æ–°çš„äº‹å®ä¸ç°æœ‰äº‹å®å†²çªæ—¶ï¼Œè‡ªåŠ¨æ ¹æ®ç­–ç•¥è§£å†³ã€‚
        
        Args:
            new_facts: æ–°æ·»åŠ çš„äº‹å®åˆ—è¡¨
                ä¾‹å¦‚: [
                    ("Erik Hort", "birthplace", "Rockland County"),
                    ("Montebello", "location", "Rockland County")
                ]
            strategy: å†²çªè§£å†³ç­–ç•¥
                - 'keep_new': æ–°å€¼è¦†ç›–æ—§å€¼ï¼ˆé»˜è®¤ï¼Œæ¨èï¼‰
                - 'keep_old': ä¿ç•™æ—§å€¼
                - 'merge': åˆå¹¶ä¸º"å¯èƒ½æ˜¯Xæˆ–Y"
                - 'keep_frequent': åŸºäºè®¿é—®é¢‘ç‡é€‰æ‹©
        
        ä½¿ç”¨åœºæ™¯ï¼š
            - å¯¼å…¥æ–°çš„æ•°æ®æº
            - æ›´æ–°è¿‡æ—¶çš„çŸ¥è¯†
            - ä¿®æ­£é”™è¯¯ä¿¡æ¯
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"API #3: å†²çªæ£€æµ‹ä¸è§£å†³ (strategy={strategy})")
        logger.info(f"{'='*80}\n")
        
        logger.info(f"ğŸ“š è¦å¯¼å…¥çš„æ–°äº‹å®:")
        for i, fact in enumerate(new_facts, 1):
            logger.info(f"   {i}. {fact}")
        
        # æ£€æµ‹å¹¶è§£å†³å†²çª
        resolution_result = self.rag.detect_and_resolve_fact_conflicts(
            new_facts=new_facts,
            resolution_strategy=strategy,
            auto_apply=True  # è‡ªåŠ¨åº”ç”¨è§£å†³æ–¹æ¡ˆ
        )
        
        logger.info(f"\nâš ï¸  å†²çªæ£€æµ‹ç»“æœï¼š")
        if 'conflicts_detected' in resolution_result:
            logger.info(f"   æ£€æµ‹åˆ° {resolution_result['conflicts_detected']} ä¸ªå†²çª")
            
            if 'conflict_records' in resolution_result:
                for record in resolution_result['conflict_records']:
                    logger.info(f"\n   å†²çªï¼š{record}")
        
        logger.info(f"\nğŸ”§ è§£å†³æ–¹æ¡ˆï¼ˆä½¿ç”¨'{strategy}'ç­–ç•¥ï¼‰ï¼š")
        if 'facts_to_delete' in resolution_result:
            logger.info(f"   è¦åˆ é™¤çš„äº‹å®: {len(resolution_result['facts_to_delete'])}")
        if 'facts_to_merge' in resolution_result:
            logger.info(f"   è¦åˆå¹¶çš„äº‹å®: {len(resolution_result['facts_to_merge'])}")
        
        logger.info(f"\nâœ… å·²åº”ç”¨è§£å†³æ–¹æ¡ˆ")
        
        # è®°å½•å†²çª
        self.conflict_records.append({
            'strategy': strategy,
            'new_facts': new_facts,
            'result': resolution_result
        })
        
        return resolution_result
    
    # ============================================================================
    # ç¬¬äº”éƒ¨åˆ†ï¼šå®Œæ•´å·¥ä½œæµæ¼”ç¤º
    # ============================================================================
    
    def complete_workflow_demo(self, queries: List[str]):
        """
        æ¼”ç¤ºå®Œæ•´çš„å·¥ä½œæµï¼š
        1. å¤šä¸ªæŸ¥è¯¢æ£€ç´¢
        2. æŸ¥çœ‹æ¿€æ´»çŠ¶æ€
        3. è‡ªåŠ¨æ¶ˆé€€
        4. å†²çªæ£€æµ‹
        5. æ‰‹åŠ¨æ¸…é™¤
        """
        logger.info("\n" + "="*80)
        logger.info("å®Œæ•´å·¥ä½œæµæ¼”ç¤º")
        logger.info("="*80)
        
        # æ­¥éª¤1ï¼šæ‰§è¡Œå¤šä¸ªæŸ¥è¯¢
        logger.info("\n[æ­¥éª¤1] æ‰§è¡Œå¤šä¸ªæŸ¥è¯¢å¹¶è®°å½•è®¿é—®å†å²")
        logger.info("-"*80)
        
        all_results = []
        for i, query in enumerate(queries, 1):
            logger.info(f"\næŸ¥è¯¢ {i}/{len(queries)}")
            results = self.retrieve_with_auto_decay(query, enable_decay=(i==len(queries)))
            all_results.append(results)
        
        # æ­¥éª¤2ï¼šæŸ¥çœ‹æœ€åä¸€ä¸ªæŸ¥è¯¢çš„æ¿€æ´»çŠ¶æ€
        if queries:
            last_query = queries[-1]
            logger.info("\n[æ­¥éª¤2] æ£€æŸ¥å†…å­˜æ¿€æ´»çŠ¶æ€")
            logger.info("-"*80)
            
            activation = self.rag.get_memory_activation_status(last_query)
            if 'error' not in activation:
                self._print_activation_status(activation)
        
        # æ­¥éª¤3ï¼šè‡ªåŠ¨æ¶ˆé€€
        if queries:
            logger.info("\n[æ­¥éª¤3] åº”ç”¨è‡ªåŠ¨æ¶ˆé€€")
            logger.info("-"*80)
            
            decay_result = self.test_auto_memory_decay(last_query, retention_ratio=0.8)
        
        # æ­¥éª¤4ï¼šå†²çªæ£€æµ‹
        logger.info("\n[æ­¥éª¤4] å†²çªæ£€æµ‹ä¸è§£å†³")
        logger.info("-"*80)
        
        new_facts = [
            ("Erik Hort", "birthplace", "Updated Location"),
            ("New Entity", "property", "value")
        ]
        conflict_result = self.test_conflict_detection_and_resolution(new_facts, strategy='keep_new')
        
        # æ­¥éª¤5ï¼šæ‰‹åŠ¨æ¸…é™¤
        if queries:
            logger.info("\n[æ­¥éª¤5] æ‰‹åŠ¨æ¸…é™¤ä½æ¿€æ´»è®°å¿†")
            logger.info("-"*80)
            
            cleanup_result = self.test_manual_cleanup(last_query, activation_threshold=0.15)
        
        logger.info("\n" + "="*80)
        logger.info("âœ… å®Œæ•´å·¥ä½œæµæ¼”ç¤ºå®Œæˆï¼")
        logger.info("="*80)
    
    # ============================================================================
    # è¾…åŠ©æ–¹æ³•
    # ============================================================================
    
    def _print_activation_status(self, activation):
        """æ‰“å°å†…å­˜æ¿€æ´»çŠ¶æ€"""
        logger.info(f"\nğŸ“Š å†…å­˜æ¿€æ´»åˆ†æ (æŸ¥è¯¢: {activation.get('current_query', 'N/A')})")
        logger.info(f"   æŸ¥è¯¢çª—å£å¤§å°: {activation.get('context_window_size', 0)}")
        
        for mem_type in ['chunk', 'entity', 'fact']:
            key = f'{mem_type}_activation'
            if key in activation:
                stats = activation[key]
                logger.info(f"\n   {mem_type.upper()}æ¿€æ´»åº¦ç»Ÿè®¡:")
                logger.info(f"      - é«˜æ¿€æ´» (>0.7): {stats.get('high_activation_count', 0)}")
                logger.info(f"      - ä¸­æ¿€æ´» (0.3-0.7): {stats.get('medium_activation_count', 0)}")
                logger.info(f"      - ä½æ¿€æ´» (0.05-0.3): {stats.get('low_activation_count', 0)}")
                logger.info(f"      - éæ´»è·ƒ (â‰¤0.05): {stats.get('inactive_count', 0)}")
                logger.info(f"      - å¹³å‡æ¿€æ´»åº¦: {stats.get('avg_activation', 0):.3f}")
    
    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        logger.info("\n" + "="*80)
        logger.info("æµ‹è¯•æ€»ç»“")
        logger.info("="*80)
        logger.info(f"æ‰§è¡Œçš„æŸ¥è¯¢æ•°: {len(self.query_history)}")
        logger.info(f"æ£€æµ‹çš„å†²çªæ•°: {len(self.conflict_records)}")
        logger.info(f"\nå·²æ‰§è¡Œçš„æŸ¥è¯¢:")
        for i, q in enumerate(self.query_history, 1):
            logger.info(f"  {i}. {q}")


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

if __name__ == "__main__":
    """
    ä½¿ç”¨ç¤ºä¾‹ï¼šé›†æˆåˆ°ä½ çš„ä¸»ç¨‹åºä¸­
    """
    
    logger.info("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘          HippoRAG è®°å¿†ç®¡ç†ç³»ç»Ÿ - é›†æˆæµ‹è¯•æŒ‡å—                              â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    ä¸‰ä¸ªæ ¸å¿ƒAPIçš„è°ƒç”¨æ–¹å¼ï¼š
    
    1ï¸âƒ£  apply_context_aware_memory_decay()
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        è‡ªåŠ¨æ¶ˆé€€ä½æ¿€æ´»è®°å¿†
        
        decay_stats = rag.apply_context_aware_memory_decay(
            current_query="Who is Erik Hort?",
            retention_ratio=0.9,      # ä¿ç•™æ¿€æ´»åº¦top-90%
            auto_forget=True          # è‡ªåŠ¨åˆ é™¤æ ‡è®°çš„è®°å¿†
        )
        
        è¿”å›: {
            'total_chunks': 100,
            'chunks_to_forget': [hash1, hash2, ...],
            'auto_forgot_chunks': 10
        }
    
    
    2ï¸âƒ£  manual_cleanup_low_activation_memories()
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        æ‰‹åŠ¨æ¸…é™¤ä½æ¿€æ´»è®°å¿†ï¼ˆå¯é€‰æ‹©æ¼”ç»ƒæ¨¡å¼ï¼‰
        
        # ç¬¬ä¸€æ­¥ï¼šé¢„è§ˆï¼ˆdry_run=Trueï¼‰
        preview = rag.manual_cleanup_low_activation_memories(
            current_query="Who is Erik Hort?",
            activation_threshold=0.1,  # ä½äº0.1çš„è®°å¿†
            dry_run=True               # ä»…é¢„è§ˆ
        )
        
        # ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œåˆ é™¤ï¼ˆdry_run=Falseï¼‰
        result = rag.manual_cleanup_low_activation_memories(
            current_query="Who is Erik Hort?",
            activation_threshold=0.1,
            dry_run=False              # æ‰§è¡Œåˆ é™¤
        )
        
        è¿”å›: {
            'chunks_to_delete': [hash1, hash2, ...],
            'actually_deleted_count': 5
        }
    
    
    3ï¸âƒ£  detect_and_resolve_fact_conflicts()
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        æ£€æµ‹å¹¶è§£å†³æ–°æ—§äº‹å®çš„å†²çª
        
        new_facts = [
            ("Erik Hort", "birthplace", "New Location"),
            ("Montebello", "location", "New County")
        ]
        
        result = rag.detect_and_resolve_fact_conflicts(
            new_facts=new_facts,
            resolution_strategy='keep_new',  # æ–°å€¼è¦†ç›–æ—§å€¼
            auto_apply=True                  # è‡ªåŠ¨åº”ç”¨è§£å†³æ–¹æ¡ˆ
        )
        
        è¿”å›: {
            'conflicts_detected': 2,
            'facts_to_delete': [...],
            'conflict_records': [...]
        }
    
    
    é›†æˆåˆ°ä½ çš„ç¨‹åºä¸­ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    from src.hipporag import HippoRAG
    
    # åˆå§‹åŒ–RAG
    rag = HippoRAG(config)
    
    # åˆ›å»ºé›†æˆæµ‹è¯•å¯¹è±¡
    test = LLMIntegrationTest(rag)
    
    # æ–¹å¼1: å•ä¸ªAPIæµ‹è¯•
    results = test.retrieve_with_auto_decay("Who is Erik Hort?")
    decay_stats = test.test_auto_memory_decay("Who is Erik Hort?")
    
    # æ–¹å¼2: å®Œæ•´å·¥ä½œæµ
    queries = [
        "Who is Erik Hort?",
        "Where was Erik born?",
        "What is Montebello?",
        "Is Montebello in Rockland County?"
    ]
    test.complete_workflow_demo(queries)
    """)
